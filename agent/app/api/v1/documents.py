from fastapi import APIRouter, HTTPException, UploadFile, File, Form, WebSocket, WebSocketDisconnect
from typing import Dict, Any, Optional, Tuple
import logging
import time
import hashlib
import shutil
import os
import threading
import asyncio
from pathlib import Path
from dataclasses import dataclass
from queue import Queue
import uuid

# TOKENIZERS_PARALLELISM ê²½ê³  í•´ê²°
os.environ["TOKENIZERS_PARALLELISM"] = "false"

# ì „ì—­ ì²˜ë¦¬ í
processing_queue = asyncio.Queue()
processing_worker_running = False

@dataclass
class ProcessingTask:
    """ì²˜ë¦¬í•  ì‘ì—… ì •ì˜"""
    task_id: str
    document_id: str
    file_content: bytes
    file_extension: str
    user_id: str
    original_filename: str
    created_at: float
    
    def __post_init__(self):
        if not self.task_id:
            self.task_id = str(uuid.uuid4())

class ProcessingProgress:
    """ë¬¸ì„œ ì²˜ë¦¬ ì§„í–‰ ìƒí™©ì„ ì¶”ì í•˜ëŠ” í´ë˜ìŠ¤"""
    
    # ì „ì—­ ì²˜ë¦¬ ìƒíƒœ ì €ì¥ì†Œ
    _progress_store = {}
    
    def __init__(self, document_id: str, filename: str):
        self.document_id = document_id
        self.filename = filename
        self.current_step = ""
        self.step_progress = 0.0
        self.total_steps = 6
        self.current_step_index = 0
        self.status = "processing"  # processing, completed, failed
        self.start_time = time.time()
        self.result_data = {}
        
        self.steps = [
            "ğŸ“¤ íŒŒì¼ ì—…ë¡œë“œ",
            "ğŸ“– PDF íŒŒì‹±", 
            "âœ‚ï¸ í…ìŠ¤íŠ¸ ì¶”ì¶œ ë° ì²­í‚¹",
            "ğŸ–¼ï¸ ì´ë¯¸ì§€ ì¶”ì¶œ",
            "ğŸ‘ï¸ OCR ì²˜ë¦¬", 
            "ğŸ§  ì„ë² ë”© ìƒì„± ë° ë²¡í„° ì €ì¥"
        ]
        
        # ì „ì—­ ì €ì¥ì†Œì— ì €ì¥
        ProcessingProgress._progress_store[document_id] = self
        
    @staticmethod
    def get_progress(document_id: str) -> Optional[Dict[str, Any]]:
        """ë¬¸ì„œ ì²˜ë¦¬ ìƒíƒœ ì¡°íšŒ"""
        progress = ProcessingProgress._progress_store.get(document_id)
        if not progress:
            return None
            
        overall_progress = (progress.current_step_index + progress.step_progress / 100.0) / progress.total_steps * 100
        
        return {
            "document_id": progress.document_id,
            "filename": progress.filename,
            "status": progress.status,
            "current_step": progress.current_step,
            "current_step_index": progress.current_step_index,
            "step_progress": progress.step_progress,
            "overall_progress": overall_progress,
            "total_steps": progress.total_steps,
            "elapsed_time": time.time() - progress.start_time,
            "result_data": progress.result_data
        }
    
    @staticmethod
    def set_completed(document_id: str, result_data: Dict[str, Any]):
        """ì²˜ë¦¬ ì™„ë£Œ ìƒíƒœë¡œ ë³€ê²½"""
        progress = ProcessingProgress._progress_store.get(document_id)
        if progress:
            progress.status = "completed"
            progress.result_data = result_data
            progress.current_step_index = progress.total_steps - 1
            progress.step_progress = 100.0
            
            # WebSocket ì™„ë£Œ ì•Œë¦¼ ì „ì†¡ (ê°„ì†Œí™”)
            try:
                import asyncio
                from app.core.websocket_manager import progress_websocket
                
                try:
                    loop = asyncio.get_running_loop()
                    print(f"ğŸ“¡ ì™„ë£Œ ë©”ì‹œì§€ ì „ì†¡ ì¤€ë¹„: {document_id} -> {result_data}", flush=True)
                    task = loop.create_task(progress_websocket.send_completion(
                        document_id,
                        "completed",
                        f"ë¬¸ì„œ ì²˜ë¦¬ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤: {progress.filename}",
                        result_data
                    ))
                    print(f"ğŸ“¡ ì™„ë£Œ ë©”ì‹œì§€ ì „ì†¡ íƒœìŠ¤í¬ ìƒì„±ë¨", flush=True)
                except RuntimeError:
                    pass
            except Exception:
                pass
    
    @staticmethod  
    def set_failed(document_id: str, error_message: str):
        """ì²˜ë¦¬ ì‹¤íŒ¨ ìƒíƒœë¡œ ë³€ê²½"""
        progress = ProcessingProgress._progress_store.get(document_id)
        if progress:
            progress.status = "failed"
            progress.result_data = {"error": error_message}
            
            # WebSocket ì‹¤íŒ¨ ì•Œë¦¼ ì „ì†¡
            try:
                import asyncio
                from app.core.websocket_manager import progress_websocket
                
                try:
                    loop = asyncio.get_running_loop()
                    loop.create_task(progress_websocket.send_completion(
                        document_id,
                        "failed",
                        f"ë¬¸ì„œ ì²˜ë¦¬ ì‹¤íŒ¨: {error_message}",
                        {"error": error_message}
                    ))
                    print(f"âŒ ë¬¸ì„œ ì²˜ë¦¬ ì‹¤íŒ¨ WebSocket ì•Œë¦¼ ì „ì†¡: {document_id}", flush=True)
                except RuntimeError:
                    print(f"âš ï¸ ì´ë²¤íŠ¸ ë£¨í”„ê°€ ì—†ì–´ WebSocket ì•Œë¦¼ ê±´ë„ˆë›°: {document_id}", flush=True)
            except Exception as e:
                print(f"âš ï¸ WebSocket ì‹¤íŒ¨ ì•Œë¦¼ ì‹¤íŒ¨: {e}", flush=True)
        
    def start_step(self, step_index: int):
        """ë‹¨ê³„ ì‹œì‘ (ë™ê¸°)"""
        self.current_step_index = step_index
        self.current_step = self.steps[step_index]
        self.step_progress = 0.0
        self._log_progress()
        self._send_websocket_progress()

    async def start_step_async(self, step_index: int):
        """ë‹¨ê³„ ì‹œì‘ (ë¹„ë™ê¸°)"""
        self.current_step_index = step_index
        self.current_step = self.steps[step_index]
        self.step_progress = 0.0
        self._log_progress()
        await self._send_websocket_progress_async()
        
    def update_step_progress(self, progress: float):
        """í˜„ì¬ ë‹¨ê³„ ì§„í–‰ë¥  ì—…ë°ì´íŠ¸ (ë™ê¸°)"""
        self.step_progress = min(100.0, max(0.0, progress))
        self._log_progress()
        self._send_websocket_progress()

    async def update_step_progress_async(self, progress: float):
        """í˜„ì¬ ë‹¨ê³„ ì§„í–‰ë¥  ì—…ë°ì´íŠ¸ (ë¹„ë™ê¸°)"""
        self.step_progress = min(100.0, max(0.0, progress))
        self._log_progress()
        await self._send_websocket_progress_async()
        
    def complete_step(self):
        """í˜„ì¬ ë‹¨ê³„ ì™„ë£Œ (ë™ê¸°)"""
        self.step_progress = 100.0
        self._log_progress()
        self._send_websocket_progress()

    async def complete_step_async(self):
        """í˜„ì¬ ë‹¨ê³„ ì™„ë£Œ (ë¹„ë™ê¸°)"""
        import asyncio
        print(f"ğŸ ë‹¨ê³„ ì™„ë£Œ ì‹œì‘: {self.current_step}", flush=True)
        self.step_progress = 100.0
        self._log_progress()
        
        # WebSocket ë©”ì‹œì§€ ì „ì†¡
        await self._send_websocket_progress_async()
        
        # ì™„ë£Œ í›„ ì•½ê°„ì˜ ëŒ€ê¸° (ë©”ì‹œì§€ ì „ì†¡ ë³´ì¥)
        await asyncio.sleep(0.1)
        print(f"âœ… ë‹¨ê³„ ì™„ë£Œë¨: {self.current_step}", flush=True)
    
    def _send_websocket_progress(self):
        """WebSocketìœ¼ë¡œ ì§„í–‰ë¥  ì „ì†¡ (ë™ê¸° - ë°±ì›Œë“œ í˜¸í™˜ì„±)"""
        try:
            import asyncio
            
            # í˜„ì¬ ì´ë²¤íŠ¸ ë£¨í”„ê°€ ìˆëŠ”ì§€ í™•ì¸
            try:
                loop = asyncio.get_running_loop()
                # ì¦‰ì‹œ ì‹¤í–‰ë˜ë„ë¡ íƒœìŠ¤í¬ ìƒì„±
                task = loop.create_task(self._send_websocket_progress_async())
                
            except RuntimeError:
                # ì´ë²¤íŠ¸ ë£¨í”„ê°€ ì—†ìœ¼ë©´ ë¬´ì‹œ
                pass
        except Exception as e:
            # WebSocket ì—ëŸ¬ëŠ” ë¬´ì‹œí•˜ê³  ê³„ì† ì§„í–‰
            pass

    async def _send_websocket_progress_async(self):
        """WebSocketìœ¼ë¡œ ì§„í–‰ë¥  ì „ì†¡ (ì¦‰ì‹œ ì‹¤í–‰)"""
        try:
            from app.core.websocket_manager import progress_websocket
            
            # ì „ì²´ ì§„í–‰ë¥  ê³„ì‚°
            overall_progress = (self.current_step_index + self.step_progress / 100.0) / self.total_steps * 100
            
            print(f"ğŸ” [DEBUG] WebSocket ì „ì†¡ ì‹œë„: document_id={self.document_id}", flush=True)
            print(f"ğŸ” [DEBUG] ë‹¨ê³„: {self.current_step}, ì§„í–‰ë¥ : {self.step_progress:.1f}%, ì „ì²´: {overall_progress:.1f}%", flush=True)
            
            await progress_websocket.send_progress(
                self.document_id,
                self.current_step,
                self.step_progress,
                overall_progress,
                f"{self.current_step_index + 1}/{self.total_steps} - {self.step_progress:.1f}%"
            )
            print(f"ğŸ“¡ WebSocket ì „ì†¡: {self.current_step} - {self.step_progress:.1f}% (ì „ì²´: {overall_progress:.1f}%)", flush=True)
                
        except Exception as e:
            print(f"âš ï¸ WebSocket ì „ì†¡ ì‹¤íŒ¨: {e}", flush=True)
            import traceback
            traceback.print_exc()
            pass

    def _log_progress(self):
        """ì§„í–‰ ìƒí™©ì„ ë¡œê·¸ë¡œ ì¶œë ¥"""
        overall_progress = (self.current_step_index + self.step_progress / 100.0) / self.total_steps * 100
        
        progress_bar = self._create_progress_bar(self.step_progress)
        
        # í„°ë¯¸ë„ê³¼ ë¡œê·¸ ëª¨ë‘ì— ì¶œë ¥
        progress_msg = f"ğŸ“‹ ì²˜ë¦¬ ì¤‘: {self.filename}"
        step_msg = f"ğŸ”„ {self.current_step}"
        step_progress_msg = f"ğŸ“Š ë‹¨ê³„ ì§„í–‰ë¥ : {progress_bar} {self.step_progress:.1f}%"
        overall_progress_msg = f"ğŸ“ˆ ì „ì²´ ì§„í–‰ë¥ : {overall_progress:.1f}% ({self.current_step_index + 1}/{self.total_steps})"
        separator = "=" * 70
        
        # í„°ë¯¸ë„ ì‹¤ì‹œê°„ ì¶œë ¥
        print(f"\n{progress_msg}", flush=True)
        print(step_msg, flush=True)
        print(step_progress_msg, flush=True)
        print(overall_progress_msg, flush=True)
        print(separator, flush=True)
        
        # ë¡œê·¸ íŒŒì¼ì—ë„ ê¸°ë¡
        logger.info(f"\n{progress_msg}")
        logger.info(step_msg)
        logger.info(step_progress_msg)
        logger.info(overall_progress_msg)
        logger.info(separator)
        
    def _create_progress_bar(self, progress: float, width: int = 30) -> str:
        """ì§„í–‰ë¥  ë°” ìƒì„±"""
        filled = int(width * progress / 100)
        bar = "â–ˆ" * filled + "â–‘" * (width - filled)
        return f"[{bar}]"

from app.core.document_processor import document_processor
from app.core.vector_store import vector_store
from app.models.schemas import ProcessingResult, DocumentUploadResponse, DocumentDeleteResponse
from app.core.config import settings

logger = logging.getLogger(__name__)
router = APIRouter()

# ë¬¸ì„œ ì²˜ë¦¬ê¸° (ì „ì—­ ì¸ìŠ¤í„´ìŠ¤)
processor = None


@router.get("/upload/{document_id}/status")
async def get_upload_status(document_id: str):
    """ë¬¸ì„œ ì²˜ë¦¬ ìƒíƒœ í™•ì¸"""
    try:
        print(f"ğŸ“Š ìƒíƒœ ì¡°íšŒ ìš”ì²­: {document_id}", flush=True)
        print(f"ğŸ“Š ì €ì¥ëœ ì§„í–‰ë¥  ê°œìˆ˜: {len(ProcessingProgress._progress_store)}", flush=True)
        print(f"ğŸ“Š ì €ì¥ëœ í‚¤ë“¤: {list(ProcessingProgress._progress_store.keys())}", flush=True)
        
        # ProcessingProgressì—ì„œ í˜„ì¬ ìƒíƒœ ì¡°íšŒ
        progress_data = ProcessingProgress.get_progress(document_id)
        
        if not progress_data:
            logger.warning(f"ì§„í–‰ë¥  ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ: {document_id}")
            raise HTTPException(
                status_code=404,
                detail="ë¬¸ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"
            )
        
        print(f"ğŸ“Š ìƒíƒœ ì¡°íšŒ ì„±ê³µ: {progress_data}", flush=True)
        return progress_data
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"ìƒíƒœ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        raise HTTPException(
            status_code=500,
            detail=f"ìƒíƒœ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
        )


@router.post("/upload", response_model=DocumentUploadResponse)
async def upload_document(
    file: UploadFile = File(...),
    user_id: str = Form("anonymous"),
    document_type: Optional[str] = Form(None)
) -> DocumentUploadResponse:
    """PDF, Word, í…ìŠ¤íŠ¸ íŒŒì¼ ì—…ë¡œë“œ - ì—…ë¡œë“œ ì™„ë£Œ í›„ ì¦‰ì‹œ ì‘ë‹µ, ì²˜ë¦¬ëŠ” ë°±ê·¸ë¼ìš´ë“œì—ì„œ"""
    start_time = time.time()
    
    try:
        # íŒŒì¼ í™•ì¥ì ê²€ì¦
        allowed_extensions = {'.pdf', '.docx', '.doc', '.txt', '.md'}
        file_extension = Path(file.filename).suffix.lower()
        
        if file_extension not in allowed_extensions:
            raise HTTPException(
                status_code=400, 
                detail=f"ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ì…ë‹ˆë‹¤. ì§€ì› í˜•ì‹: {', '.join(allowed_extensions)}"
            )
        
        # íŒŒì¼ í¬ê¸° ê²€ì¦ (50MB ì œí•œ)
        max_size = getattr(settings, 'MAX_FILE_SIZE', 52428800)  # 50MB
        if hasattr(file, 'size') and file.size > max_size:
            raise HTTPException(
                status_code=413, 
                detail=f"íŒŒì¼ì´ ë„ˆë¬´ í½ë‹ˆë‹¤. ìµœëŒ€ {max_size // 1024 // 1024}MBê¹Œì§€ ì§€ì›í•©ë‹ˆë‹¤."
            )
        
        # ê³ ìœ  ë¬¸ì„œ ID ìƒì„±
        file_hash = hashlib.md5(f"{user_id}_{file.filename}_{time.time()}".encode()).hexdigest()
        
        # ì§„í–‰ ìƒí™© ì¶”ì  ì‹œì‘
        progress = ProcessingProgress(file_hash, file.filename)
        await progress.start_step_async(0)  # íŒŒì¼ ì—…ë¡œë“œ
        
        # íŒŒì¼ ë‚´ìš©ì„ ë©”ëª¨ë¦¬ì—ì„œ ì§ì ‘ ì½ê¸°
        file_content = await file.read()
        await progress.complete_step_async()
        
        print(f"\nâœ… íŒŒì¼ ì—…ë¡œë“œ ì™„ë£Œ: {file.filename} (í¬ê¸°: {len(file_content):,} bytes)", flush=True)
        logger.info(f"íŒŒì¼ ì—…ë¡œë“œ ì™„ë£Œ: {file.filename} (í¬ê¸°: {len(file_content)} bytes, ì‚¬ìš©ì: {user_id})")
        
        # ì²˜ë¦¬ ì‘ì—…ì„ íì— ì¶”ê°€
        task = ProcessingTask(
            task_id="",  # __post_init__ì—ì„œ ìë™ ìƒì„±
            document_id=file_hash,
            file_content=file_content,
            file_extension=file_extension,
            user_id=user_id,
            original_filename=file.filename,
            created_at=time.time()
        )
        
        # íì— ì‘ì—… ì¶”ê°€
        await processing_queue.put(task)
        
        # ì²˜ë¦¬ ì›Œì»¤ê°€ ì‹¤í–‰ ì¤‘ì´ ì•„ë‹ˆë©´ ì‹œì‘
        await ensure_processing_worker_running()
        
        print(f"ğŸ“‹ ì²˜ë¦¬ ì‘ì—… íì— ì¶”ê°€ë¨: {file.filename} (ì‘ì—… ID: {task.task_id})", flush=True)
        
        # ì—…ë¡œë“œ ì™„ë£Œ í›„ ì¦‰ì‹œ ì‘ë‹µ ë°˜í™˜ (ì²˜ë¦¬ëŠ” ì›Œì»¤ì—ì„œ ì§„í–‰)
        return DocumentUploadResponse(
            document_id=file_hash,
            filename=file.filename,
            status="processing",
            message=f"íŒŒì¼ '{file.filename}' ì—…ë¡œë“œ ì™„ë£Œ. ë¬¸ì„œ ì²˜ë¦¬ê°€ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤.",
            processing_time=time.time() - start_time
        )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"íŒŒì¼ ì—…ë¡œë“œ ì‹¤íŒ¨: {e}")
        raise HTTPException(
            status_code=500,
            detail=f"íŒŒì¼ ì—…ë¡œë“œ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
        )


async def ensure_processing_worker_running():
    """ì²˜ë¦¬ ì›Œì»¤ê°€ ì‹¤í–‰ ì¤‘ì´ ì•„ë‹ˆë©´ ì‹œì‘"""
    global processing_worker_running
    
    if not processing_worker_running:
        processing_worker_running = True
        asyncio.create_task(document_processing_worker())
        logger.info("ğŸ“„ ë¬¸ì„œ ì²˜ë¦¬ ì›Œì»¤ ì‹œì‘ë¨")


async def document_processing_worker():
    """ë¬¸ì„œ ì²˜ë¦¬ë¥¼ ë‹´ë‹¹í•˜ëŠ” ì›Œì»¤ (íì—ì„œ ì‘ì—…ì„ ê°€ì ¸ì™€ ì²˜ë¦¬)"""
    global processing_worker_running
    
    logger.info("ğŸ”„ ë¬¸ì„œ ì²˜ë¦¬ ì›Œì»¤ ì‹¤í–‰ ì¤‘...")
    print("ğŸ”„ ë¬¸ì„œ ì²˜ë¦¬ ì›Œì»¤ ì‹œì‘!", flush=True)
    
    while processing_worker_running:
        try:
            print("ğŸ“‹ íì—ì„œ ì‘ì—… ëŒ€ê¸° ì¤‘...", flush=True)
            # íì—ì„œ ì‘ì—… ê°€ì ¸ì˜¤ê¸° (íƒ€ì„ì•„ì›ƒ ì„¤ì • - ë” ê¸¸ê²Œ)
            task = await asyncio.wait_for(processing_queue.get(), timeout=300.0)  # 5ë¶„ìœ¼ë¡œ ì—°ì¥
            
            print(f"ğŸ“‹ ì²˜ë¦¬ ì‹œì‘: {task.original_filename} (ë¬¸ì„œ ID: {task.document_id})", flush=True)
            logger.info(f"ğŸ“‹ ì²˜ë¦¬ ì‹œì‘: {task.original_filename} (ë¬¸ì„œ ID: {task.document_id})")
            
            # ì§„í–‰ ìƒí™© ì¶”ì  ì‹œì‘
            progress = ProcessingProgress(task.document_id, task.original_filename)
            print(f"ğŸ“Š ì§„í–‰ ìƒí™© ì¶”ì  ì‹œì‘: {task.document_id}", flush=True)
            
            # ë¬¸ì„œ ì²˜ë¦¬ ì‹¤í–‰
            await _process_document_with_progress(task, progress)
            
            # ì‘ì—… ì™„ë£Œ í‘œì‹œ
            processing_queue.task_done()
            print(f"âœ… ì‘ì—… ì™„ë£Œ: {task.original_filename}", flush=True)
            
        except asyncio.TimeoutError:
            # 5ë¶„ ë™ì•ˆ ìƒˆ ì‘ì—…ì´ ì—†ìœ¼ë©´ ì›Œì»¤ ì¢…ë£Œ
            print("â° ì²˜ë¦¬ ì›Œì»¤ íƒ€ì„ì•„ì›ƒ - ì›Œì»¤ ì¢…ë£Œ", flush=True)
            logger.info("â° ì²˜ë¦¬ ì›Œì»¤ íƒ€ì„ì•„ì›ƒ - ì›Œì»¤ ì¢…ë£Œ")
            break
        except Exception as e:
            logger.error(f"ì²˜ë¦¬ ì›Œì»¤ ì˜¤ë¥˜: {e}")
            # ì‘ì—… ì™„ë£Œ í‘œì‹œ (ì˜¤ë¥˜ ë°œìƒí•´ë„)
            try:
                processing_queue.task_done()
            except:
                pass
            continue
    
    processing_worker_running = False
    logger.info("ğŸ›‘ ë¬¸ì„œ ì²˜ë¦¬ ì›Œì»¤ ì¢…ë£Œë¨")


async def _process_document_with_progress(task: ProcessingTask, progress: ProcessingProgress):
    """ì§„í–‰ ìƒí™©ê³¼ í•¨ê»˜ ë¬¸ì„œ ì²˜ë¦¬"""
    try:
        print(f"\nğŸ”„ ë¬¸ì„œ ì²˜ë¦¬ ì‹œì‘: {task.original_filename}", flush=True)
        print(f"ğŸ“Š ì§„í–‰ ìƒí™© ê°ì²´ ìƒì„±: {progress.document_id}", flush=True)
        logger.info(f"ë¬¸ì„œ ì²˜ë¦¬ ì‹œì‘: {task.original_filename}")
        
        # WebSocket ì—°ê²° í™•ì¸ ë° ëŒ€ê¸°
        await _wait_for_websocket_connection(task.document_id, timeout=10)
        
        # ê¸°ì¡´ ë¬¸ì„œ ì²˜ë¦¬ ë¡œì§ ì‹¤í–‰
        print(f"ğŸš€ _process_and_store_document_from_memory í˜¸ì¶œ ì‹œì‘", flush=True)
        processing_result = await _process_and_store_document_from_memory(
            file_content=task.file_content,
            file_extension=task.file_extension,
            user_id=task.user_id,
            document_id=task.document_id,
            original_filename=task.original_filename,
            progress=progress
        )
        print(f"ğŸš€ _process_and_store_document_from_memory ì™„ë£Œ: {processing_result}", flush=True)
        
        # ì™„ë£Œ ìƒíƒœ ì—…ë°ì´íŠ¸
        result_data = {
            "text_chunks": processing_result.get("text_chunks", 0),
            "image_chunks": processing_result.get("image_chunks", 0), 
            "total_embeddings": processing_result.get("total_embeddings", 0),
            "processing_time": time.time() - progress.start_time
        }
        print(f"ğŸ“Š ì™„ë£Œ ìƒíƒœ ì—…ë°ì´íŠ¸: {result_data}", flush=True)
        
        # WebSocket ì—°ê²°ì„ ë‹¤ì‹œ í™•ì¸í•˜ê³  ì™„ë£Œ ë©”ì‹œì§€ ì „ì†¡
        await _ensure_completion_message_sent(task.document_id, result_data, progress.filename)
        
        ProcessingProgress.set_completed(task.document_id, result_data)
        
        print(f"\nâœ… ë¬¸ì„œ ì²˜ë¦¬ ì™„ë£Œ: {task.original_filename}", flush=True)
        logger.info(f"ë¬¸ì„œ ì²˜ë¦¬ ì™„ë£Œ: {task.original_filename}")
        
    except Exception as e:
        print(f"\nâŒ ì²˜ë¦¬ ì‹¤íŒ¨: {task.original_filename} - {e}", flush=True)
        logger.error(f"ë¬¸ì„œ ì²˜ë¦¬ ì‹¤íŒ¨: {task.original_filename} - {e}")
        
        # ì‹¤íŒ¨ ìƒíƒœ ì—…ë°ì´íŠ¸
        ProcessingProgress.set_failed(task.document_id, str(e))


@router.post("/process-document", response_model=Dict[str, Any])
async def process_document(
    file_path: str,
    user_id: str
) -> Dict[str, Any]:
    """Backendì—ì„œ í˜¸ì¶œí•˜ëŠ” ë¬¸ì„œ ì²˜ë¦¬ ì—”ë“œí¬ì¸íŠ¸"""
    global processor
    
    start_time = time.time()
    
    try:
        # ì…ë ¥ ê²€ì¦
        if not file_path.strip():
            raise HTTPException(status_code=400, detail="íŒŒì¼ ê²½ë¡œê°€ í•„ìš”í•©ë‹ˆë‹¤")
        
        if not user_id.strip():
            raise HTTPException(status_code=400, detail="ì‚¬ìš©ì IDê°€ í•„ìš”í•©ë‹ˆë‹¤")
        
        # íŒŒì¼ ì¡´ì¬ í™•ì¸
        if not Path(file_path).exists():
            raise HTTPException(status_code=404, detail=f"íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {file_path}")
        
        logger.info(f"ë¬¸ì„œ ì²˜ë¦¬ ì‹œì‘: {file_path} (ì‚¬ìš©ì: {user_id})")
        
        # ë¬¸ì„œ ì²˜ë¦¬ê¸° ì´ˆê¸°í™” (ì§€ì—° ë¡œë”©)
        if processor is None:
            # TODO: ì‹¤ì œ MultiModalDocumentProcessor êµ¬í˜„ í›„ ì‚¬ìš©
            # processor = MultiModalDocumentProcessor()
            # await processor.initialize()
            pass
        
        # ì„ì‹œ êµ¬í˜„: ê°„ë‹¨í•œ í…ìŠ¤íŠ¸ ì²˜ë¦¬
        result = await _process_simple_document(file_path, user_id)
        
        # ë²¡í„° DBì— ì €ì¥
        collection_name = f"documents_{user_id}"
        
        # ì„ë² ë”©ì´ ìˆëŠ” ì²­í¬ë“¤ë§Œ ì €ì¥
        all_chunks = result.text_chunks + result.image_chunks
        if all_chunks:
            stored_count = await vector_store.store_embeddings(collection_name, all_chunks)
        else:
            stored_count = 0
        
        processing_time = time.time() - start_time
        
        # ë¬¸ì„œ ID ìƒì„±
        document_id = hashlib.md5(f"{file_path}_{user_id}".encode()).hexdigest()
        
        response = {
            "document_id": document_id,
            "status": "processed",
            "text_chunks": len(result.text_chunks),
            "image_chunks": len(result.image_chunks),
            "total_embeddings": stored_count,
            "processing_time": processing_time
        }
        
        logger.info(f"ë¬¸ì„œ ì²˜ë¦¬ ì™„ë£Œ: {response}")
        return response
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"ë¬¸ì„œ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
        raise HTTPException(
            status_code=500,
            detail=f"ë¬¸ì„œ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
        )


async def _process_and_store_document_from_memory(
    file_content: bytes,
    file_extension: str,
    user_id: str, 
    document_id: str, 
    original_filename: str,
    progress: ProcessingProgress
) -> Dict[str, Any]:
    """ë©”ëª¨ë¦¬ì˜ íŒŒì¼ ë‚´ìš©ì„ ì§ì ‘ ì²˜ë¦¬í•˜ê³  Qdrant ë²¡í„° DBì— ì €ì¥"""
    from app.core.embedding_manager import embedding_manager
    from app.models.schemas import DocumentChunk
    import uuid
    from datetime import datetime
    
    try:
        # ì´ë¯¸ ì´ˆê¸°í™”ëœ ì„œë¹„ìŠ¤ë“¤ ì‚¬ìš©
        from app.core.rag_engine import rag_engine
        
        # RAG ì—”ì§„ì´ ì´ˆê¸°í™”ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸
        if not rag_engine._initialized:
            print("\nğŸ”„ RAG ì—”ì§„ ì´ˆê¸°í™” ì‹œì‘...", flush=True)
            logger.info("RAG ì—”ì§„ì´ ì´ˆê¸°í™”ë˜ì§€ ì•ŠìŒ. ì´ˆê¸°í™” ì‹œì‘...")
            await rag_engine.initialize()
            print("âœ… RAG ì—”ì§„ ì´ˆê¸°í™” ì™„ë£Œ!", flush=True)
        else:
            print("âœ… ì´ë¯¸ ì´ˆê¸°í™”ëœ RAG ì—”ì§„ ì‚¬ìš©", flush=True)
            logger.info("ì´ë¯¸ ì´ˆê¸°í™”ëœ RAG ì—”ì§„ ì‚¬ìš©")
        
        text_chunks = 0
        image_chunks = 0
        chunks = []
        
        if file_extension in ['.txt', '.md']:
            # í…ìŠ¤íŠ¸ íŒŒì¼ ì²˜ë¦¬
            await progress.start_step_async(1)  # PDF íŒŒì‹± (í…ìŠ¤íŠ¸ëŠ” ê±´ë„ˆë›´)
            await progress.complete_step_async()
            
            await progress.start_step_async(2)  # í…ìŠ¤íŠ¸ ì¶”ì¶œ ë° ì²­í‚¹
            
            try:
                content = file_content.decode('utf-8')
            except UnicodeDecodeError:
                # UTF-8 ë””ì½”ë”© ì‹¤íŒ¨ ì‹œ ë‹¤ë¥¸ ì¸ì½”ë”© ì‹œë„
                try:
                    content = file_content.decode('cp949')  # í•œêµ­ì–´ ì¸ì½”ë”©
                except UnicodeDecodeError:
                    content = file_content.decode('latin-1', errors='ignore')
            
            await progress.update_step_progress_async(50.0)
            await progress._send_websocket_progress_async()
            
            chunks = await _process_text_content_from_string(
                content, document_id, original_filename, rag_engine.embedding_manager
            )
            text_chunks = len(chunks)
            
            await progress.complete_step_async()
            await progress._send_websocket_progress_async()
            
            # ì´ë¯¸ì§€ ì¶”ì¶œ ë‹¨ê³„ëŠ” ê±´ë„ˆë›´
            await progress.start_step_async(3)  # ì´ë¯¸ì§€ ì¶”ì¶œ
            await progress.complete_step_async()
            await progress.start_step_async(4)  # OCR ì²˜ë¦¬
            await progress.complete_step_async()
            
        elif file_extension == '.pdf':
            # PDF íŒŒì¼ì„ ì„ì‹œë¡œ ì €ì¥í•´ì„œ ì²˜ë¦¬ (PyMuPDF ë“±ì´ íŒŒì¼ ê²½ë¡œ í•„ìš”)
            import tempfile
            import os
            
            await progress.start_step_async(1)  # PDF íŒŒì‹±
            await progress.update_step_progress_async(20.0)
            await progress._send_websocket_progress_async()
            
            # ì´ë²¤íŠ¸ ë£¨í”„ ì–‘ë³´
            import asyncio
            await asyncio.sleep(0.01)
            
            with tempfile.NamedTemporaryFile(delete=False, suffix='.pdf') as temp_file:
                temp_file.write(file_content)
                temp_path = temp_file.name
            
            await progress.update_step_progress_async(60.0)
            await progress._send_websocket_progress_async()
            
            try:
                chunks, image_count = await _process_pdf_with_images(
                    temp_path, document_id, original_filename, progress, rag_engine.embedding_manager
                )
                text_chunks = len([c for c in chunks if c.metadata.get('content_type') == 'text'])
                image_chunks = len([c for c in chunks if c.metadata.get('content_type') == 'image'])
            finally:
                # ì„ì‹œ íŒŒì¼ ì‚­ì œ
                if os.path.exists(temp_path):
                    os.unlink(temp_path)
            
            progress.complete_step()
            await progress._send_websocket_progress_async()
                    
        else:
            # ê¸°íƒ€ íŒŒì¼ì€ í…ìŠ¤íŠ¸ë¡œ ì²˜ë¦¬ ì‹œë„
            await progress.start_step_async(1)  # PDF íŒŒì‹± (ê±´ë„ˆë›´)
            await progress.complete_step_async()
            
            await progress.start_step_async(2)  # í…ìŠ¤íŠ¸ ì¶”ì¶œ ë° ì²­í‚¹
            
            try:
                content = file_content.decode('utf-8', errors='ignore')
                chunks = await _process_text_content_from_string(
                    content, document_id, original_filename, rag_engine.embedding_manager
                )
                text_chunks = len(chunks)
            except Exception as e:
                logger.warning(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ ì²˜ë¦¬ ì‹¤íŒ¨: {file_extension}, {e}")
                chunks = []
            
            await progress.complete_step_async()
            
            # ì´ë¯¸ì§€ ì¶”ì¶œ ë‹¨ê³„ëŠ” ê±´ë„ˆë›´
            await progress.start_step_async(3)  # ì´ë¯¸ì§€ ì¶”ì¶œ
            await progress.complete_step_async()
            await progress.start_step_async(4)  # OCR ì²˜ë¦¬
            await progress.complete_step_async()
        
        # ë²¡í„° DBì— ì €ì¥
        if chunks:
            await progress.start_step_async(5)  # ë²¡í„° ì €ì¥
            await progress.update_step_progress_async(50.0)
            await progress._send_websocket_progress_async()
            
            # ì´ë²¤íŠ¸ ë£¨í”„ ì–‘ë³´
            await asyncio.sleep(0.01)
            
            await rag_engine.vector_store.add_documents(chunks, user_id)
            
            await progress.complete_step_async()
            await progress._send_websocket_progress_async()
            print(f"\nğŸ’¾ Qdrantì— {len(chunks):,}ê°œ ì²­í¬ ì €ì¥ ì™„ë£Œ: {original_filename}", flush=True)
            logger.info(f"Qdrantì— {len(chunks)}ê°œ ì²­í¬ ì €ì¥ ì™„ë£Œ: {original_filename}")
        
        # ìµœì¢… WebSocket ë©”ì‹œì§€ ì „ì†¡ì„ ìœ„í•œ ì´ë²¤íŠ¸ ë£¨í”„ ì–‘ë³´
        import asyncio
        await asyncio.sleep(0.01)
        
        # ëª¨ë“  ë‹¨ê³„ ì™„ë£Œ - ì „ì²´ ì§„í–‰ë¥  100%ë¡œ ì„¤ì •
        progress.current_step_index = progress.total_steps - 1
        progress.step_progress = 100.0
        await progress._send_websocket_progress_async()
        
        # ìµœì¢… ì™„ë£Œ ë©”ì‹œì§€ ì „ì†¡ì„ ìœ„í•œ ì¶”ê°€ ì‹œê°„
        await asyncio.sleep(0.02)
        
        return {
            "text_chunks": text_chunks,
            "image_chunks": image_chunks,
            "total_embeddings": len(chunks)
        }
        
    except Exception as e:
        logger.error(f"ë©”ëª¨ë¦¬ íŒŒì¼ ì²˜ë¦¬ ë° ì €ì¥ ì‹¤íŒ¨: {e}")
        raise


async def _process_text_content_from_string(
    content: str, 
    document_id: str, 
    original_filename: str,
    embedding_manager
) -> list:
    """ë¬¸ìì—´ ì½˜í…ì¸ ë¥¼ ì²­í¬ë¡œ ë‚˜ëˆ„ê³  ì„ë² ë”© ìƒì„± (íŒŒì¼ ê²½ë¡œ ì—†ì´)"""
    from app.models.schemas import DocumentChunk
    import uuid
    from datetime import datetime
    
    chunks = []
    chunk_size = 1000  # 1000ì ë‹¨ìœ„ë¡œ ì²­í‚¹
    
    for i in range(0, len(content), chunk_size):
        chunk_text = content[i:i+chunk_size].strip()
        if not chunk_text:
            continue
            
        # ì„ë² ë”© ìƒì„±
        embedding = await embedding_manager.embed_text(chunk_text)
        
        chunk = DocumentChunk(
            id=str(uuid.uuid4()),
            content=chunk_text,
            embedding=embedding,
            metadata={
                "document_id": document_id,
                "original_filename": original_filename,
                "chunk_index": len(chunks),
                "file_type": "text",
                "created_at": str(datetime.now())
            }
        )
        chunks.append(chunk)
    
    return chunks


async def _process_and_store_document(
    file_path: str, 
    user_id: str, 
    document_id: str, 
    original_filename: str
) -> Dict[str, Any]:
    """ë¬¸ì„œë¥¼ ì²˜ë¦¬í•˜ê³  Qdrant ë²¡í„° DBì— ì €ì¥"""
    from app.core.embedding_manager import embedding_manager
    from app.models.schemas import DocumentChunk
    import uuid
    from datetime import datetime
    
    try:
        # ì„ë² ë”© ë§¤ë‹ˆì €ì™€ ë²¡í„° ìŠ¤í† ì–´ ì´ˆê¸°í™”
        await embedding_manager.initialize()
        await vector_store.initialize()
        
        # íŒŒì¼ í™•ì¥ìì— ë”°ë¥¸ ì²˜ë¦¬
        file_extension = Path(file_path).suffix.lower()
        text_chunks = 0
        image_chunks = 0
        
        if file_extension == '.txt' or file_extension == '.md':
            # í…ìŠ¤íŠ¸ íŒŒì¼ ì²˜ë¦¬
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            chunks = await _process_text_content(
                content, file_path, document_id, original_filename
            )
            text_chunks = len(chunks)
            
        elif file_extension == '.pdf':
            # PDF íŒŒì¼ ì²˜ë¦¬ (í…ìŠ¤íŠ¸ + ì´ë¯¸ì§€ + OCR)
            chunks, image_count = await _process_pdf_with_images(
                file_path, document_id, original_filename
            )
            text_chunks = len([c for c in chunks if c.metadata.get('content_type') == 'text'])
            image_chunks = len([c for c in chunks if c.metadata.get('content_type') == 'image'])
                    
        else:
            # ê¸°íƒ€ íŒŒì¼ì€ í…ìŠ¤íŠ¸ë¡œ ì½ê¸° ì‹œë„
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    content = f.read()
                chunks = await _process_text_content(
                    content, file_path, document_id, original_filename
                )
                text_chunks = len(chunks)
            except:
                logger.warning(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹: {file_extension}")
                chunks = []
        
        # ë²¡í„° DBì— ì €ì¥
        if chunks:
            await vector_store.add_documents(chunks, user_id)
            logger.info(f"Qdrantì— {len(chunks)}ê°œ ì²­í¬ ì €ì¥ ì™„ë£Œ: {original_filename}")
        
        return {
            "text_chunks": text_chunks,
            "image_chunks": image_chunks,
            "total_embeddings": len(chunks)
        }
        
    except Exception as e:
        logger.error(f"ë¬¸ì„œ ì²˜ë¦¬ ë° ì €ì¥ ì‹¤íŒ¨: {e}")
        raise


async def _process_text_content(
    content: str, 
    file_path: str, 
    document_id: str, 
    original_filename: str
) -> list:
    """í…ìŠ¤íŠ¸ ì½˜í…ì¸ ë¥¼ ì²­í¬ë¡œ ë‚˜ëˆ„ê³  ì„ë² ë”© ìƒì„±"""
    from app.core.embedding_manager import embedding_manager
    from app.models.schemas import DocumentChunk
    import uuid
    from datetime import datetime
    
    chunks = []
    chunk_size = 1000  # 1000ì ë‹¨ìœ„ë¡œ ì²­í‚¹
    
    for i in range(0, len(content), chunk_size):
        chunk_text = content[i:i+chunk_size].strip()
        if not chunk_text:
            continue
            
        # ì„ë² ë”© ìƒì„±
        embedding = await embedding_manager.embed_text(chunk_text)
        
        chunk = DocumentChunk(
            id=str(uuid.uuid4()),
            content=chunk_text,
            embedding=embedding,
            metadata={
                "document_id": document_id,
                "file_path": file_path,
                "original_filename": original_filename,
                "chunk_index": len(chunks),
                "file_type": "text",
                "created_at": str(datetime.now())
            }
        )
        chunks.append(chunk)
    
    return chunks


async def _process_pdf_with_images(
    file_path: str, 
    document_id: str, 
    original_filename: str,
    progress: ProcessingProgress,
    embedding_manager
) -> Tuple[list, int]:
    """ê³ ê¸‰ PDF ì²˜ë¦¬: í…ìŠ¤íŠ¸ì™€ ì´ë¯¸ì§€ë¥¼ ëª¨ë‘ ì²˜ë¦¬ (OCR í¬í•¨)"""
    from app.core.document_processor import document_processor
    from app.models.schemas import DocumentChunk
    import uuid
    from datetime import datetime
    import fitz  # PyMuPDF
    
    chunks = []
    image_count = 0
    
    try:
        # PyMuPDFë¥¼ ì‚¬ìš©í•´ì„œ PDF ì—´ê¸° (ì´ë¯¸ì§€ ì¶”ì¶œ ê°€ëŠ¥)
        pdf_document = fitz.open(file_path)
        total_pages = len(pdf_document)
        
        progress.start_step(2)  # í…ìŠ¤íŠ¸ ì¶”ì¶œ ë° ì²­í‚¹
        
        # í…ìŠ¤íŠ¸ ì¶”ì¶œ ë° ì²­í‚¹ ë‹¨ê³„ - ëŒ€ìš©ëŸ‰ íŒŒì¼ ëŒ€ì‘
        processed_pages = 0
        max_chunks_per_batch = 20  # ë°°ì¹˜ í¬ê¸° ì¦ê°€ (ëŒ€ìš©ëŸ‰ ì²˜ë¦¬ìš©)
        batch_chunks = []
        
        for page_num in range(min(total_pages, 1000)):  # ìµœëŒ€ 1000í˜ì´ì§€ë¡œ ì œí•œ
            try:
                page = pdf_document[page_num]
                
                # í˜ì´ì§€ë³„ ì§„í–‰ë¥  ê³„ì‚° ë° ì—…ë°ì´íŠ¸ (ë§ˆì§€ë§‰ í˜ì´ì§€ ê³ ë ¤)
                total_to_process = min(total_pages, 1000)
                if page_num == total_to_process - 1:  # ë§ˆì§€ë§‰ í˜ì´ì§€
                    text_progress = 99.0  # ë§ˆì§€ë§‰ì€ 99%ë¡œ ì„¤ì •
                else:
                    text_progress = (page_num / total_to_process) * 99.0  # 99%ê¹Œì§€ë§Œ ì§„í–‰
                await progress.update_step_progress_async(text_progress)
                
                # ì´ë²¤íŠ¸ ë£¨í”„ ì–‘ë³´ - ëŒ€ìš©ëŸ‰ íŒŒì¼ ì²˜ë¦¬ ì‹œ ë” ìì£¼ ì–‘ë³´
                import asyncio
                if page_num % 10 == 0:  # 10í˜ì´ì§€ë§ˆë‹¤ ë” ê¸´ ëŒ€ê¸°
                    await asyncio.sleep(0.05)
                else:
                    await asyncio.sleep(0.001)  # ê¸°ë³¸ ëŒ€ê¸° ì‹œê°„ ë‹¨ì¶•
                
                # 1. í…ìŠ¤íŠ¸ ì¶”ì¶œ
                page_text = page.get_text().strip()
                if page_text and len(page_text) > 20:  # ìµœì†Œ ê¸¸ì´ ì²´í¬
                    # í…ìŠ¤íŠ¸ë¥¼ ì²­í¬ë¡œ ë‚˜ëˆ„ê¸° (ë” í° ì²­í¬ ì‚¬ìš©)
                    chunk_size = 2000
                    page_chunks_text = []
                    
                    for i in range(0, len(page_text), chunk_size):
                        chunk_text = page_text[i:i+chunk_size].strip()
                        if chunk_text and len(chunk_text) > 10:
                            page_chunks_text.append(chunk_text)
                    
                    # ì„ë² ë”© ìƒì„± (ë°°ì¹˜ë¡œ ì²˜ë¦¬)
                    for chunk_text in page_chunks_text[:5]:  # í˜ì´ì§€ë‹¹ ìµœëŒ€ 5ê°œ ì²­í¬
                        try:
                            # ì„ë² ë”© ìƒì„± ì „ ì´ë²¤íŠ¸ ë£¨í”„ ì–‘ë³´ (ë¸”ë¡œí‚¹ ë°©ì§€)
                            await asyncio.sleep(0.001)
                            embedding = await embedding_manager.embed_text(chunk_text)
                            
                            chunk = DocumentChunk(
                                id=str(uuid.uuid4()),
                                content=chunk_text,
                                embedding=embedding,
                                metadata={
                                    "document_id": document_id,
                                    "file_path": file_path,
                                    "original_filename": original_filename,
                                    "page": page_num + 1,
                                    "chunk_index": len(chunks),
                                    "content_type": "text",
                                    "file_type": "pdf",
                                    "created_at": str(datetime.now())
                                }
                            )
                            batch_chunks.append(chunk)
                            
                            # ë°°ì¹˜ ì²˜ë¦¬
                            if len(batch_chunks) >= max_chunks_per_batch:
                                chunks.extend(batch_chunks)
                                batch_chunks = []
                                print(f"ğŸ“„ PDF í…ìŠ¤íŠ¸ ì²˜ë¦¬: {len(chunks)}ê°œ ì²­í¬ ì™„ë£Œ", flush=True)
                                await asyncio.sleep(0.05)  # ë°°ì¹˜ ì²˜ë¦¬ í›„ ëŒ€ê¸° ì‹œê°„ ë‹¨ì¶•
                            
                        except Exception as embed_error:
                            logger.warning(f"í…ìŠ¤íŠ¸ ì„ë² ë”© ì‹¤íŒ¨ (í˜ì´ì§€ {page_num + 1}): {embed_error}")
                            continue
                
                processed_pages += 1
                
                # 50í˜ì´ì§€ë§ˆë‹¤ ì§„í–‰ ìƒí™© ì¶œë ¥ (1000í˜ì´ì§€ ì²˜ë¦¬ ì‹œ ë„ˆë¬´ ë§ì€ ë¡œê·¸ ë°©ì§€)
                if processed_pages % 50 == 0:
                    print(f"ğŸ“– PDF ì²˜ë¦¬ ì§„í–‰: {processed_pages}/{min(total_pages, 1000)} í˜ì´ì§€ ì™„ë£Œ ({text_progress:.1f}%)", flush=True)
                    
            except Exception as page_error:
                logger.warning(f"PDF í˜ì´ì§€ {page_num + 1} ì²˜ë¦¬ ì‹¤íŒ¨: {page_error}")
                continue
        
        # ë‚¨ì€ ë°°ì¹˜ ì²˜ë¦¬
        if batch_chunks:
            chunks.extend(batch_chunks)
        
        # í…ìŠ¤íŠ¸ ì²˜ë¦¬ ì™„ë£Œ ì „ì— 100% ì§„í–‰ë¥  ì—…ë°ì´íŠ¸
        print(f"ğŸ”„ í…ìŠ¤íŠ¸ ì²˜ë¦¬ ì™„ë£Œ ì¤‘... (100%)", flush=True)
        await progress.update_step_progress_async(100.0)
        await asyncio.sleep(0.1)  # ì§„í–‰ë¥  ì—…ë°ì´íŠ¸ ì „ì†¡ ì‹œê°„ í™•ë³´
        
        print(f"âœ… í…ìŠ¤íŠ¸ ì²˜ë¦¬ ë‹¨ê³„ ì™„ë£Œ!", flush=True)
        await progress.complete_step_async()  # í…ìŠ¤íŠ¸ ì¶”ì¶œ ì™„ë£Œ
        
        # ì´ë¯¸ì§€ ì²˜ë¦¬ ì‹œì‘
        await progress.start_step_async(3)  # ì´ë¯¸ì§€ ì¶”ì¶œ
        print(f"ğŸ“· ì´ë¯¸ì§€ ì²˜ë¦¬ ì‹œì‘...", flush=True)
        
        # ì´ë¯¸ì§€ ì¶”ì¶œ ë° OCR ì²˜ë¦¬
        for page_num in range(min(total_pages, 1000)):  # ìµœëŒ€ 1000í˜ì´ì§€ì˜ ì´ë¯¸ì§€ ì²˜ë¦¬
            try:
                page = pdf_document[page_num]
                image_list = page.get_images()
                
                if image_list:
                    print(f"ğŸ“· í˜ì´ì§€ {page_num + 1}: {len(image_list)}ê°œ ì´ë¯¸ì§€ ë°œê²¬", flush=True)
                
                for img_index, img in enumerate(image_list[:10]):  # í˜ì´ì§€ë‹¹ ìµœëŒ€ 10ê°œ ì´ë¯¸ì§€
                    try:
                        # ì´ë¯¸ì§€ ì¶”ì¶œ
                        xref = img[0]
                        pix = fitz.Pixmap(pdf_document, xref)
                        
                        if pix.n - pix.alpha < 4:  # GRAY ë˜ëŠ” RGB
                            # ì´ë¯¸ì§€ë¥¼ PIL Imageë¡œ ë³€í™˜
                            img_data = pix.tobytes("png")
                            
                            # ë„ë©´/ê¸°ìˆ  ë¬¸ì„œìš© ì´ë¯¸ì§€ í’ˆì§ˆ ê°œì„ 
                            enhanced_img_data = await _enhance_technical_image(img_data, page_num + 1, img_index + 1)
                            
                            # ì´ë¯¸ì§€ ë©”íƒ€ë°ì´í„°ë§Œ ì €ì¥ (ê°„ì†Œí™”)
                            image_metadata = {
                                "document_id": document_id,
                                "original_filename": original_filename,
                                "page": page_num + 1,
                                "image_index": img_index,
                                "chunk_index": len(chunks),
                                "content_type": "image",
                                "file_type": "pdf",
                                "image_size": len(enhanced_img_data),
                                "original_size": len(img_data),
                                "enhanced": True,
                                "created_at": str(datetime.now())
                            }
                            
                            # ê°„ë‹¨í•œ ì´ë¯¸ì§€ ì²­í¬ ìƒì„± (ì„ë² ë”© ì—†ì´)
                            image_content = f"Enhanced technical image from page {page_num + 1}, image {img_index + 1}"
                            if enhanced_img_data != img_data:
                                image_content += " (upscaled and enhanced)"
                            
                            image_chunk = DocumentChunk(
                                id=str(uuid.uuid4()),
                                content=image_content,
                                embedding=[0.0] * 768,  # ë”ë¯¸ ì„ë² ë”©
                                metadata=image_metadata
                            )
                            chunks.append(image_chunk)
                            image_count += 1
                            
                            if enhanced_img_data != img_data:
                                print(f"ğŸ” ì´ë¯¸ì§€ í’ˆì§ˆ ê°œì„  ì™„ë£Œ: í˜ì´ì§€ {page_num + 1}, ì´ë¯¸ì§€ {img_index + 1}", flush=True)
                            else:
                                print(f"ğŸ–¼ï¸ ì´ë¯¸ì§€ ì¶”ê°€: í˜ì´ì§€ {page_num + 1}, ì´ë¯¸ì§€ {img_index + 1}", flush=True)
                        
                        # ë©”ëª¨ë¦¬ ì •ë¦¬ (ëŒ€ìš©ëŸ‰ íŒŒì¼ ì²˜ë¦¬ ì‹œ ì¤‘ìš”)
                        if pix:
                            pix = None
                        
                        # 100ê°œ ì´ë¯¸ì§€ë§ˆë‹¤ ê°€ë¹„ì§€ ì»¬ë ‰ì…˜ (ë©”ëª¨ë¦¬ ìµœì í™”)
                        if image_count % 100 == 0 and image_count > 0:
                            import gc
                            gc.collect()
                            print(f"ğŸ—‘ï¸ ë©”ëª¨ë¦¬ ì •ë¦¬ ì™„ë£Œ ({image_count}ê°œ ì´ë¯¸ì§€ ì²˜ë¦¬ë¨)", flush=True)
                        
                    except Exception as img_error:
                        logger.warning(f"ì´ë¯¸ì§€ ì²˜ë¦¬ ì‹¤íŒ¨ (í˜ì´ì§€ {page_num + 1}, ì´ë¯¸ì§€ {img_index + 1}): {img_error}")
                        continue
                        
                # ì§„í–‰ë¥  ì—…ë°ì´íŠ¸
                image_progress = (page_num / min(total_pages, 1000)) * 100
                await progress.update_step_progress_async(image_progress)
                        
            except Exception as page_error:
                logger.warning(f"í˜ì´ì§€ {page_num + 1} ì´ë¯¸ì§€ ì²˜ë¦¬ ì‹¤íŒ¨: {page_error}")
                continue
                
        await progress.complete_step_async()  # ì´ë¯¸ì§€ ì²˜ë¦¬ ì™„ë£Œ
        
        await progress.start_step_async(4)  # OCR ì²˜ë¦¬
        print(f"ğŸ” OCR ì²˜ë¦¬ ê±´ë„ˆë›°ê¸° (ì„±ëŠ¥ ìµœì í™”)", flush=True)
        await progress.complete_step_async()
        
        pdf_document.close()
        
        print(f"ğŸ“‹ PDF ì²˜ë¦¬ ì™„ë£Œ: {len(chunks)}ê°œ ì²­í¬ ìƒì„± (í…ìŠ¤íŠ¸: {len(chunks) - image_count}, ì´ë¯¸ì§€: {image_count})")
        logger.info(f"PDF ì²˜ë¦¬ ì™„ë£Œ: {len(chunks)}ê°œ ì²­í¬ (í…ìŠ¤íŠ¸: {len(chunks) - image_count}, ì´ë¯¸ì§€: {image_count}ê°œ í¬í•¨)")
        return chunks, image_count
        
        
    except Exception as e:
        logger.warning(f"PDF ì²˜ë¦¬ ì‹¤íŒ¨, ê°„ë‹¨í•œ í…ìŠ¤íŠ¸ ì¶”ì¶œë¡œ ëŒ€ì²´: {e}")
        # Fallback: ê¸°ë³¸ í…ìŠ¤íŠ¸ë§Œ ì¶”ì¶œ
        try:
            simple_chunks = await _process_pdf_file_simple(file_path, document_id, original_filename, embedding_manager)
            logger.info(f"PDF ê°„ë‹¨ í…ìŠ¤íŠ¸ ì²˜ë¦¬ ì™„ë£Œ: {len(simple_chunks)}ê°œ ì²­í¬")
            return simple_chunks, 0
        except Exception as fallback_e:
            logger.error(f"PDF í…ìŠ¤íŠ¸ ì²˜ë¦¬ ì™„ì „ ì‹¤íŒ¨: {fallback_e}")
            return [], 0


async def _process_pdf_file_simple(file_path: str, document_id: str, original_filename: str, embedding_manager) -> list:
    """ê°„ë‹¨í•œ PDF í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
    import PyPDF2
    from app.models.schemas import DocumentChunk
    import uuid
    from datetime import datetime
    
    chunks = []
    
    try:
        with open(file_path, 'rb') as pdf_file:
            pdf_reader = PyPDF2.PdfReader(pdf_file)
            
            for page_num, page in enumerate(pdf_reader.pages[:20]):  # ìµœëŒ€ 20í˜ì´ì§€
                try:
                    page_text = page.extract_text().strip()
                    if page_text and len(page_text) > 50:
                        # í° ì²­í¬ ë‹¨ìœ„ë¡œ ì²˜ë¦¬
                        chunk_size = 2000
                        for i in range(0, len(page_text), chunk_size):
                            chunk_text = page_text[i:i+chunk_size].strip()
                            if chunk_text and len(chunk_text) > 20:
                                
                                embedding = await embedding_manager.embed_text(chunk_text)
                                
                                chunk = DocumentChunk(
                                    id=str(uuid.uuid4()),
                                    content=chunk_text,
                                    embedding=embedding,
                                    metadata={
                                        "document_id": document_id,
                                        "original_filename": original_filename,
                                        "page": page_num + 1,
                                        "chunk_index": len(chunks),
                                        "file_type": "pdf",
                                        "created_at": str(datetime.now())
                                    }
                                )
                                chunks.append(chunk)
                                
                except Exception as e:
                    logger.warning(f"PDF í˜ì´ì§€ {page_num + 1} ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
                    continue
                    
        return chunks
        
    except Exception as e:
        logger.error(f"PDF íŒŒì¼ ì½ê¸° ì‹¤íŒ¨: {e}")
        return []


async def _enhance_technical_image(img_data: bytes, page_num: int, img_index: int) -> bytes:
    """ê¸°ìˆ  ë„ë©´/ë„í‘œìš© ì´ë¯¸ì§€ í’ˆì§ˆ í–¥ìƒ"""
    try:
        from PIL import Image, ImageEnhance, ImageFilter
        import io
        
        # PIL Imageë¡œ ë³€í™˜
        image = Image.open(io.BytesIO(img_data))
        original_size = image.size
        
        # ë„ë©´/ê¸°ìˆ  ë¬¸ì„œ íŠ¹ì„± ê°ì§€
        is_technical_drawing = _detect_technical_drawing(image)
        
        # ì´ë¯¸ì§€ê°€ ë„ˆë¬´ ì‘ìœ¼ë©´ ì—…ìŠ¤ì¼€ì¼ë§ (ë„ë©´ íŠ¹ì„±ìƒ í•´ìƒë„ ì¤‘ìš”)
        min_dimension = 1200 if is_technical_drawing else 800  # ë„ë©´ì´ë©´ ë” ë†’ì€ í•´ìƒë„ ìš”êµ¬
        max_dimension = max(image.size)
        
        if max_dimension < min_dimension:
            # ì—…ìŠ¤ì¼€ì¼ë§ ë¹„ìœ¨ ê³„ì‚°
            scale_factor = min_dimension / max_dimension
            new_size = (int(image.width * scale_factor), int(image.height * scale_factor))
            
            print(f"ğŸ” ì´ë¯¸ì§€ ì—…ìŠ¤ì¼€ì¼ë§: {original_size} â†’ {new_size} (í˜ì´ì§€ {page_num}, ì´ë¯¸ì§€ {img_index})", flush=True)
            
            # ê³ í’ˆì§ˆ ì—…ìŠ¤ì¼€ì¼ë§ (LANCZOS ì‚¬ìš©)
            image = image.resize(new_size, Image.Resampling.LANCZOS)
        
        # ë„ë©´/ê¸°ìˆ  ë¬¸ì„œì— ìµœì í™”ëœ í›„ì²˜ë¦¬
        enhancement_factor = 1.4 if is_technical_drawing else 1.2
        
        # 1. ëŒ€ë¹„ í–¥ìƒ (ë„ë©´ì˜ ì„ ëª…ë„ ê°œì„ )
        if image.mode in ['L', 'RGB']:  # ê·¸ë ˆì´ìŠ¤ì¼€ì¼ ë˜ëŠ” ì»¬ëŸ¬ ì´ë¯¸ì§€
            enhancer = ImageEnhance.Contrast(image)
            image = enhancer.enhance(enhancement_factor)  # ë„ë©´ì´ë©´ ë” ê°•í•œ ëŒ€ë¹„
        
        # 2. ì„ ëª…ë„ í–¥ìƒ (ë„ë©´ ë¼ì¸ ê°•í™”)
        if image.mode in ['L', 'RGB']:
            enhancer = ImageEnhance.Sharpness(image)
            sharpness_factor = 1.5 if is_technical_drawing else 1.3
            image = enhancer.enhance(sharpness_factor)  # ë„ë©´ì´ë©´ ë” ê°•í•œ ì„ ëª…ë„
        
        # 3. ë„ë©´ìš© ì—ì§€ ê°•í™”
        if is_technical_drawing and max_dimension > 400:
            # ë„ë©´ì˜ ë¼ì¸ì„ ë”ìš± ì„ ëª…í•˜ê²Œ
            image = image.filter(ImageFilter.UnsharpMask(radius=1, percent=150, threshold=3))
        
        # 4. ë…¸ì´ì¦ˆ ì œê±° (ìŠ¤ìº”ëœ ë„ë©´ì˜ ì¡ìŒ ì œê±°)
        elif max_dimension > 300:  # ì¼ë°˜ ì´ë¯¸ì§€
            image = image.filter(ImageFilter.MedianFilter(size=3))
        
        # ê²°ê³¼ë¥¼ ë°”ì´íŠ¸ë¡œ ë³€í™˜
        output_buffer = io.BytesIO()
        # PNGë¡œ ì €ì¥ (ë¬´ì†ì‹¤, ë„ë©´ì— ì í•©)
        if image.mode in ['RGBA', 'LA']:
            image.save(output_buffer, format='PNG')
        else:
            image.save(output_buffer, format='PNG')
        
        enhanced_data = output_buffer.getvalue()
        
        # ê°œì„  ê²°ê³¼ ë¡œê·¸
        improvement_ratio = len(enhanced_data) / len(img_data) if len(img_data) > 0 else 1
        drawing_type = "ê¸°ìˆ ë„ë©´" if is_technical_drawing else "ì¼ë°˜ì´ë¯¸ì§€"
        print(f"ğŸ“ˆ {drawing_type} í’ˆì§ˆ ê°œì„  ì™„ë£Œ: {len(img_data):,} â†’ {len(enhanced_data):,} bytes (x{improvement_ratio:.1f})", flush=True)
        
        return enhanced_data
        
    except Exception as e:
        print(f"âš ï¸ ì´ë¯¸ì§€ í’ˆì§ˆ ê°œì„  ì‹¤íŒ¨ (í˜ì´ì§€ {page_num}, ì´ë¯¸ì§€ {img_index}): {e}", flush=True)
        # ì‹¤íŒ¨ ì‹œ ì›ë³¸ ì´ë¯¸ì§€ ë°ì´í„° ë°˜í™˜
        return img_data


async def _wait_for_websocket_connection(document_id: str, timeout: int = 10):
    """WebSocket ì—°ê²°ì„ ê¸°ë‹¤ë¦¼"""
    from app.core.websocket_manager import progress_websocket
    
    start_time = time.time()
    while time.time() - start_time < timeout:
        if document_id in progress_websocket.connections and len(progress_websocket.connections[document_id]) > 0:
            print(f"âœ… WebSocket ì—°ê²° í™•ì¸ë¨: {document_id}", flush=True)
            return True
        
        print(f"â³ WebSocket ì—°ê²° ëŒ€ê¸° ì¤‘... ({int(time.time() - start_time)}ì´ˆ)", flush=True)
        await asyncio.sleep(1)
    
    print(f"âš ï¸ WebSocket ì—°ê²° íƒ€ì„ì•„ì›ƒ: {document_id}", flush=True)
    return False


async def _ensure_completion_message_sent(document_id: str, result_data: dict, filename: str):
    """ì™„ë£Œ ë©”ì‹œì§€ê°€ í™•ì‹¤íˆ ì „ì†¡ë˜ë„ë¡ ë³´ì¥"""
    from app.core.websocket_manager import progress_websocket
    
    max_retries = 5
    retry_count = 0
    
    while retry_count < max_retries:
        try:
            # ì—°ê²° ìƒíƒœ í™•ì¸
            if document_id in progress_websocket.connections and len(progress_websocket.connections[document_id]) > 0:
                print(f"ğŸ“¡ ì™„ë£Œ ë©”ì‹œì§€ ì „ì†¡ ì‹œë„ {retry_count + 1}/{max_retries}: {document_id}", flush=True)
                
                # ì™„ë£Œ ë©”ì‹œì§€ ì „ì†¡
                await progress_websocket.send_completion(
                    document_id,
                    "completed", 
                    f"ë¬¸ì„œ ì²˜ë¦¬ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤: {filename}",
                    result_data
                )
                
                print(f"âœ… ì™„ë£Œ ë©”ì‹œì§€ ì „ì†¡ ì„±ê³µ!", flush=True)
                return True
            else:
                print(f"ğŸ“¡ WebSocket ì—°ê²° ì—†ìŒ, ì¬ì—°ê²° ëŒ€ê¸°... ({retry_count + 1}/{max_retries})", flush=True)
                
            await asyncio.sleep(2)  # 2ì´ˆ ëŒ€ê¸° í›„ ì¬ì‹œë„
            retry_count += 1
            
        except Exception as e:
            print(f"âš ï¸ ì™„ë£Œ ë©”ì‹œì§€ ì „ì†¡ ì‹¤íŒ¨ ({retry_count + 1}/{max_retries}): {e}", flush=True)
            retry_count += 1
            await asyncio.sleep(1)
    
    print(f"âŒ ì™„ë£Œ ë©”ì‹œì§€ ì „ì†¡ ìµœì¢… ì‹¤íŒ¨: {document_id}", flush=True)
    return False


def _detect_technical_drawing(image) -> bool:
    """ì´ë¯¸ì§€ê°€ ê¸°ìˆ  ë„ë©´ì¸ì§€ ê°ì§€"""
    try:
        # ê·¸ë ˆì´ìŠ¤ì¼€ì¼ë¡œ ë³€í™˜
        if image.mode != 'L':
            gray_image = image.convert('L')
        else:
            gray_image = image
        
        # ì´ë¯¸ì§€ í¬ê¸°
        width, height = gray_image.size
        
        # ë„ˆë¬´ ì‘ì€ ì´ë¯¸ì§€ëŠ” ë„ë©´ì´ ì•„ë‹ ê°€ëŠ¥ì„±ì´ ë†’ìŒ
        if width < 200 or height < 200:
            return False
        
        # íˆìŠ¤í† ê·¸ë¨ ë¶„ì„
        histogram = gray_image.histogram()
        
        # í‘ë°± í”½ì…€ì˜ ë¹„ìœ¨ ê³„ì‚°
        total_pixels = width * height
        black_pixels = sum(histogram[0:50])  # ì–´ë‘ìš´ í”½ì…€
        white_pixels = sum(histogram[200:256])  # ë°ì€ í”½ì…€
        
        # ë„ë©´ íŠ¹ì§•: ëŒ€ë¶€ë¶„ í°ìƒ‰ ë°°ê²½ì— ê²€ì€ìƒ‰ ì„ 
        white_ratio = white_pixels / total_pixels
        black_ratio = black_pixels / total_pixels
        
        # ë„ë©´ íŒë³„ ì¡°ê±´
        # 1. í°ìƒ‰ ë°°ê²½ì´ 60% ì´ìƒ
        # 2. ê²€ì€ìƒ‰ ì„ ì´ 10% ì´ìƒ
        # 3. ì¤‘ê°„ í†¤ì´ ì ìŒ (ì„ ëª…í•œ ëŒ€ë¹„)
        middle_tones = sum(histogram[50:200]) / total_pixels
        
        is_drawing = (white_ratio > 0.6 and 
                     black_ratio > 0.05 and 
                     middle_tones < 0.3)
        
        if is_drawing:
            print(f"ğŸ—ï¸ ê¸°ìˆ ë„ë©´ ê°ì§€ë¨: ë°±ìƒ‰ {white_ratio:.2f}, í‘ìƒ‰ {black_ratio:.2f}, ì¤‘ê°„í†¤ {middle_tones:.2f}", flush=True)
        
        return is_drawing
        
    except Exception as e:
        print(f"âš ï¸ ë„ë©´ ê°ì§€ ì‹¤íŒ¨: {e}", flush=True)
        return False



async def _delete_document_from_vector_db(collection_name: str, document_id: str) -> int:
    """ë²¡í„° DBì—ì„œ íŠ¹ì • document_idë¥¼ ê°€ì§„ ëª¨ë“  ì ë“¤ ì‚­ì œ"""
    try:
        # ë¨¼ì € í•´ë‹¹ document_idë¥¼ ê°€ì§„ ëª¨ë“  ì ë“¤ ì°¾ê¸°
        from app.core.embedding_manager import embedding_manager
        await embedding_manager.initialize()
        
        # ë”ë¯¸ ê²€ìƒ‰ìœ¼ë¡œ ëª¨ë“  ì  ê°€ì ¸ì˜¤ê¸°
        test_embedding = await embedding_manager.embed_text("test")
        all_docs = await vector_store.search_similar(
            collection_name=collection_name,
            query_vector=test_embedding,
            limit=10000,  # ì¶©ë¶„íˆ í° ìˆ˜
            score_threshold=0.0
        )
        
        # document_idê°€ ì¼ì¹˜í•˜ëŠ” ì ë“¤ì˜ ID ìˆ˜ì§‘
        points_to_delete = []
        for doc in all_docs:
            if doc.metadata.get("document_id") == document_id:
                points_to_delete.append(doc.document_id)  # Qdrant point ID
        
        # ì ë“¤ ì‚­ì œ
        if points_to_delete:
            # Qdrantì—ì„œ ì ë“¤ ì‚­ì œ
            await vector_store.client.delete(
                collection_name=collection_name,
                points_selector={"points": points_to_delete}
            )
            logger.info(f"ë²¡í„° DBì—ì„œ {len(points_to_delete)}ê°œ ì  ì‚­ì œ ì™„ë£Œ: {document_id}")
        
        return len(points_to_delete)
        
    except Exception as e:
        logger.error(f"ë²¡í„° DB ì‚­ì œ ì‹¤íŒ¨: {e}")
        return 0


async def _delete_document_by_filename(collection_name: str, filename: str) -> int:
    """ë²¡í„° DBì—ì„œ íŠ¹ì • filenameì„ ê°€ì§„ ëª¨ë“  ì ë“¤ ì‚­ì œ"""
    try:
        # Qdrantì—ì„œ ì§ì ‘ í•„í„°ë§ìœ¼ë¡œ ì°¾ê¸° (ë” íš¨ìœ¨ì )
        from qdrant_client.models import Filter, FieldCondition, MatchValue
        
        # ë‹¤ì–‘í•œ í•„í„° ì¡°ê±´ ì‹œë„
        filters_to_try = [
            # original_filenameìœ¼ë¡œ ì •í™•íˆ ë§¤ì¹­
            Filter(must=[FieldCondition(key="original_filename", match=MatchValue(value=filename))]),
            # filenameìœ¼ë¡œ ì •í™•íˆ ë§¤ì¹­  
            Filter(must=[FieldCondition(key="filename", match=MatchValue(value=filename))]),
        ]
        
        total_deleted = 0
        
        for i, filter_condition in enumerate(filters_to_try):
            try:
                logger.info(f"ì‚­ì œ ì‹œë„ {i+1}: í•„í„° ì¡°ê±´ìœ¼ë¡œ '{filename}' ê²€ìƒ‰")
                
                # ì¡°ê±´ì— ë§ëŠ” ì ë“¤ ê²€ìƒ‰
                search_result = await vector_store.client.scroll(
                    collection_name=collection_name,
                    scroll_filter=filter_condition,
                    limit=10000,
                    with_payload=True,
                    with_vectors=False
                )
                
                points_found = search_result[0] if search_result else []
                logger.info(f"í•„í„° {i+1}ë¡œ ì°¾ì€ ì  ìˆ˜: {len(points_found)}")
                
                if points_found:
                    # ì ë“¤ì˜ ID ìˆ˜ì§‘
                    point_ids = [point.id for point in points_found]
                    
                    # ì‹¤ì œ ì‚­ì œ ì‹¤í–‰
                    delete_result = await vector_store.client.delete(
                        collection_name=collection_name,
                        points_selector={"points": point_ids}
                    )
                    
                    deleted_count = len(point_ids)
                    total_deleted += deleted_count
                    
                    logger.info(f"í•„í„° {i+1}ë¡œ {deleted_count}ê°œ ì  ì‚­ì œ ì™„ë£Œ")
                    
                    # ì²« ë²ˆì§¸ ì„±ê³µí•œ í•„í„°ë¡œ ì‚­ì œëìœ¼ë©´ ë‚˜ë¨¸ì§€ëŠ” ì‹œë„í•˜ì§€ ì•ŠìŒ
                    if deleted_count > 0:
                        logger.info(f"'{filename}' ì‚­ì œ ì„±ê³µ: ì´ {total_deleted}ê°œ ì  ì‚­ì œë¨")
                        return total_deleted
                        
            except Exception as filter_error:
                logger.warning(f"í•„í„° {i+1} ì‚­ì œ ì‹œë„ ì‹¤íŒ¨: {filter_error}")
                continue
        
        # í•„í„°ë§ìœ¼ë¡œ ì•ˆ ë˜ë©´ ì „ì²´ ê²€ìƒ‰ í›„ ë§¤ì¹­ (fallback)
        if total_deleted == 0:
            logger.info("í•„í„°ë§ ì‹¤íŒ¨, ì „ì²´ ê²€ìƒ‰ìœ¼ë¡œ fallback")
            
            from app.core.embedding_manager import embedding_manager
            await embedding_manager.initialize()
            
            # ë”ë¯¸ ê²€ìƒ‰ìœ¼ë¡œ ëª¨ë“  ì  ê°€ì ¸ì˜¤ê¸°
            test_embedding = await embedding_manager.embed_text("test")
            all_docs = await vector_store.search_similar(
                collection_name=collection_name,
                query_vector=test_embedding,
                limit=10000,
                score_threshold=0.0
            )
            
            logger.info(f"ì „ì²´ ê²€ìƒ‰ìœ¼ë¡œ {len(all_docs)}ê°œ ë¬¸ì„œ í™•ì¸")
            
            # filenameì´ ì¼ì¹˜í•˜ëŠ” ì ë“¤ ì°¾ê¸°
            points_to_delete = []
            
            for doc in all_docs:
                doc_filename = doc.metadata.get("filename", "")
                doc_original_filename = doc.metadata.get("original_filename", "")
                
                # ë‹¨ìˆœí•˜ê³  í™•ì‹¤í•œ ë§¤ì¹­
                if (doc_original_filename == filename or 
                    doc_filename == filename or
                    os.path.basename(doc_original_filename) == filename or
                    os.path.basename(doc_filename) == filename):
                    
                    points_to_delete.append(doc.document_id)
                    logger.info(f"ë§¤ì¹­ ë°œê²¬: original='{doc_original_filename}', filename='{doc_filename}'")
            
            # ì‚­ì œ ì‹¤í–‰
            if points_to_delete:
                await vector_store.client.delete(
                    collection_name=collection_name,
                    points_selector={"points": points_to_delete}
                )
                total_deleted = len(points_to_delete)
                logger.info(f"Fallbackìœ¼ë¡œ {total_deleted}ê°œ ì  ì‚­ì œ ì™„ë£Œ")
            else:
                logger.warning(f"'{filename}' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ")
        
        return total_deleted
        
    except Exception as e:
        logger.error(f"ë²¡í„° DB íŒŒì¼ëª… ê¸°ë°˜ ì‚­ì œ ì‹¤íŒ¨: {e}")
        return 0


async def _process_pdf_file(
    file_path: str, 
    document_id: str, 
    original_filename: str
) -> list:
    """PDF íŒŒì¼ ì²˜ë¦¬"""
    import PyPDF2
    from app.core.embedding_manager import embedding_manager
    from app.models.schemas import DocumentChunk
    import uuid
    from datetime import datetime
    
    chunks = []
    
    with open(file_path, 'rb') as pdf_file:
        pdf_reader = PyPDF2.PdfReader(pdf_file)
        
        for page_num, page in enumerate(pdf_reader.pages):
            try:
                page_text = page.extract_text().strip()
                if not page_text:
                    continue
                
                # í˜ì´ì§€ë³„ë¡œ ì²­í‚¹ (í° í˜ì´ì§€ëŠ” ë” ë‚˜ëˆŒ ìˆ˜ ìˆìŒ)
                chunk_size = 1500
                for i in range(0, len(page_text), chunk_size):
                    chunk_text = page_text[i:i+chunk_size].strip()
                    if not chunk_text:
                        continue
                    
                    # ì„ë² ë”© ìƒì„±
                    embedding = await embedding_manager.embed_text(chunk_text)
                    
                    chunk = DocumentChunk(
                        id=str(uuid.uuid4()),
                        content=chunk_text,
                        embedding=embedding,
                        metadata={
                            "document_id": document_id,
                            "file_path": file_path,
                            "original_filename": original_filename,
                            "page": page_num + 1,
                            "chunk_index": len(chunks),
                            "file_type": "pdf",
                            "created_at": str(datetime.now())
                        }
                    )
                    chunks.append(chunk)
                    
            except Exception as e:
                logger.warning(f"PDF í˜ì´ì§€ {page_num + 1} ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
                continue
    
    return chunks


async def _process_simple_document(file_path: str, user_id: str) -> ProcessingResult:
    """ì„ì‹œ êµ¬í˜„: ê°„ë‹¨í•œ ë¬¸ì„œ ì²˜ë¦¬"""
    from app.core.embedding_manager import embedding_manager
    from app.models.schemas import DocumentChunk
    import uuid
    from datetime import datetime
    
    try:
        # ì„ë² ë”© ë§¤ë‹ˆì € ì´ˆê¸°í™”
        await embedding_manager.initialize()
        
        # íŒŒì¼ í™•ì¥ìì— ë”°ë¥¸ ê°„ë‹¨í•œ ì²˜ë¦¬
        file_extension = Path(file_path).suffix.lower()
        
        if file_extension == '.txt':
            # í…ìŠ¤íŠ¸ íŒŒì¼ ì½ê¸°
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # ê°„ë‹¨í•œ ì²­í‚¹ (1000ì ë‹¨ìœ„)
            chunks = []
            for i in range(0, len(content), 1000):
                chunk_text = content[i:i+1000]
                if chunk_text.strip():
                    # ì„ë² ë”© ìƒì„±
                    embedding = await embedding_manager.embed_text(chunk_text)
                    
                    chunk = DocumentChunk(
                        id=str(uuid.uuid4()),
                        content=chunk_text,
                        embedding=embedding,
                        metadata={
                            "file_path": file_path,
                            "chunk_index": len(chunks),
                            "file_type": "text"
                        }
                    )
                    chunks.append(chunk)
            
            return ProcessingResult(
                text_chunks=chunks,
                image_chunks=[],
                total_embeddings=len(chunks)
            )
        
        else:
            # ë‹¤ë¥¸ íŒŒì¼ í˜•ì‹ì€ ì•„ì§ ë¯¸êµ¬í˜„
            raise HTTPException(
                status_code=400,
                detail=f"ì•„ì§ ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ì…ë‹ˆë‹¤: {file_extension}"
            )
            
    except Exception as e:
        logger.error(f"ê°„ë‹¨ ë¬¸ì„œ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
        raise


@router.get("/status/{document_id}")
async def get_document_status(document_id: str):
    """ë¬¸ì„œ ì²˜ë¦¬ ìƒíƒœ ì¡°íšŒ"""
    # TODO: ì‹¤ì œ ë¬¸ì„œ ìƒíƒœ ì¶”ì  ì‹œìŠ¤í…œ êµ¬í˜„
    return {
        "document_id": document_id,
        "status": "completed",
        "message": "ë¬¸ì„œ ì²˜ë¦¬ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤"
    }


@router.get("/list")
async def list_documents(user_id: str = "anonymous") -> Dict[str, Any]:
    """ì—…ë¡œë“œëœ ë¬¸ì„œ ëª©ë¡ ì¡°íšŒ - ë²¡í„° DBì—ì„œ ì‹¤ì œ ì €ì¥ëœ ë¬¸ì„œ í™•ì¸"""
    try:
        # ë²¡í„° DB ì´ˆê¸°í™”
        await vector_store.initialize()
        
        # ì‚¬ìš©ìë³„ ì»¬ë ‰ì…˜ëª…
        collection_name = f"documents_{user_id}"
        
        try:
            # ì»¬ë ‰ì…˜ ì¡´ì¬ í™•ì¸
            await vector_store.ensure_collection(collection_name)
            
            # ë²¡í„° DBì—ì„œ ëª¨ë“  ë¬¸ì„œ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
            from app.core.embedding_manager import embedding_manager
            await embedding_manager.initialize()
            
            # ë”ë¯¸ ì„ë² ë”©ìœ¼ë¡œ ëª¨ë“  ë¬¸ì„œ ê²€ìƒ‰ (score_threshold=0.0ìœ¼ë¡œ ëª¨ë“  ê²°ê³¼ ë°˜í™˜)
            test_embedding = await embedding_manager.embed_text("test")
            all_docs = await vector_store.search_similar(
                collection_name=collection_name,
                query_vector=test_embedding,
                limit=1000,  # ì¶©ë¶„íˆ í° ìˆ˜
                score_threshold=0.0  # ëª¨ë“  ë¬¸ì„œ ë°˜í™˜
            )
            
            # ë¬¸ì„œë³„ë¡œ ê·¸ë£¹í™”
            doc_groups = {}
            for doc in all_docs:
                doc_id = doc.metadata.get("document_id", "unknown")
                filename = doc.metadata.get("original_filename", "Unknown")
                
                if doc_id not in doc_groups:
                    doc_groups[doc_id] = {
                        "document_id": doc_id,
                        "original_filename": filename,
                        "file_path": doc.metadata.get("file_path", ""),
                        "file_type": doc.metadata.get("file_type", "unknown"),
                        "created_at": doc.metadata.get("created_at", ""),
                        "chunks": 0,
                        "total_content_length": 0
                    }
                
                doc_groups[doc_id]["chunks"] += 1
                doc_groups[doc_id]["total_content_length"] += len(doc.content)
            
            # ì‘ë‹µ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
            uploaded_files = []
            for doc_info in doc_groups.values():
                uploaded_files.append({
                    "filename": f"{doc_info['document_id']}_{doc_info['original_filename']}",
                    "original_name": doc_info["original_filename"],
                    "document_id": doc_info["document_id"],
                    "chunks": doc_info["chunks"],
                    "content_length": doc_info["total_content_length"],
                    "uploaded_at": doc_info["created_at"][:19] if doc_info["created_at"] else "",
                    "file_type": doc_info["file_type"],
                    "stored_in_vector_db": True
                })
            
            return {
                "files": uploaded_files,
                "total_count": len(uploaded_files),
                "collection_name": collection_name,
                "total_chunks": sum(doc["chunks"] for doc in uploaded_files)
            }
            
        except Exception as vector_error:
            logger.error(f"ë²¡í„° DBì—ì„œ ë¬¸ì„œ ì¡°íšŒ ì‹¤íŒ¨: {vector_error}")
            raise HTTPException(
                status_code=500,
                detail=f"ë¬¸ì„œ ëª©ë¡ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(vector_error)}"
            )
        
    except Exception as e:
        logger.error(f"íŒŒì¼ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        raise HTTPException(
            status_code=500,
            detail=f"íŒŒì¼ ëª©ë¡ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
        )


@router.delete("/delete/{document_id}")
async def delete_document(document_id: str, user_id: str = "anonymous") -> DocumentDeleteResponse:
    """ì—…ë¡œë“œëœ ë¬¸ì„œ ì‚­ì œ - ë²¡í„° DBì—ì„œë§Œ ì‚­ì œ (íŒŒì¼ ì‹œìŠ¤í…œ ì‚¬ìš© ì•ˆí•¨)"""
    try:
        # ë²¡í„° DBì—ì„œ ë¬¸ì„œ ì‚­ì œ
        deleted_from_vector_db = False
        deleted_count = 0
        
        try:
            # ë²¡í„° DB ì´ˆê¸°í™”
            await vector_store.initialize()
            collection_name = f"documents_{user_id}"
            
            # í•´ë‹¹ document_idë¥¼ ê°€ì§„ ëª¨ë“  ì ë“¤ ì‚­ì œ
            deleted_count = await _delete_document_from_vector_db(collection_name, document_id)
            
            if deleted_count > 0:
                deleted_from_vector_db = True
                logger.info(f"ë²¡í„° DBì—ì„œ {deleted_count}ê°œ ì²­í¬ ì‚­ì œ: {document_id}")
            else:
                logger.warning(f"ì‚­ì œí•  ë¬¸ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ: {document_id}")
                
        except Exception as vector_error:
            logger.error(f"ë²¡í„° DB ì‚­ì œ ì‹¤íŒ¨: {vector_error}")
            raise HTTPException(
                status_code=500,
                detail=f"ë¬¸ì„œ ì‚­ì œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(vector_error)}"
            )
        
        if deleted_from_vector_db:
            message = f"ë¬¸ì„œ '{document_id}'ê°€ ì„±ê³µì ìœ¼ë¡œ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤. ({deleted_count}ê°œ ì²­í¬ ì‚­ì œë¨)"
            success = True
        else:
            message = f"ë¬¸ì„œ '{document_id}'ë¥¼ ì°¾ì„ ìˆ˜ ì—†ì–´ ì‚­ì œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
            success = False
            
        return DocumentDeleteResponse(
            message=message, 
            deleted_chunks=deleted_count,
            success=success
        )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"íŒŒì¼ ì‚­ì œ ì‹¤íŒ¨: {e}")
        raise HTTPException(
            status_code=500,
            detail=f"ë¬¸ì„œ ì‚­ì œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
        )


@router.delete("/clear-all")
async def clear_all_documents(user_id: str = "anonymous") -> DocumentDeleteResponse:
    """ì‚¬ìš©ìì˜ ëª¨ë“  ë¬¸ì„œë¥¼ ë²¡í„° DBì—ì„œ ì‚­ì œ"""
    try:
        deleted_count = 0
        
        try:
            # ë²¡í„° DB ì´ˆê¸°í™”
            await vector_store.initialize()
            collection_name = f"documents_{user_id}"
            
            # ì»¬ë ‰ì…˜ ì „ì²´ ì‚­ì œ ì‹œë„
            try:
                # ì»¬ë ‰ì…˜ì´ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
                import asyncio
                collections = await asyncio.to_thread(vector_store.client.get_collections)
                collection_exists = any(col.name == collection_name for col in collections.collections)
                
                if collection_exists:
                    # ì»¬ë ‰ì…˜ ì‚­ì œ
                    await asyncio.to_thread(vector_store.client.delete_collection, collection_name)
                    logger.info(f"ì»¬ë ‰ì…˜ '{collection_name}' ì „ì²´ ì‚­ì œ ì™„ë£Œ")
                    
                    # ìƒˆë¡œìš´ ë¹ˆ ì»¬ë ‰ì…˜ ìƒì„±
                    await vector_store._create_collection(collection_name)
                    logger.info(f"ìƒˆë¡œìš´ ë¹ˆ ì»¬ë ‰ì…˜ '{collection_name}' ìƒì„± ì™„ë£Œ")
                    
                    deleted_count = "ì „ì²´"  # ì „ì²´ ì‚­ì œë¥¼ í‘œì‹œ
                    message = f"ì‚¬ìš©ì '{user_id}'ì˜ ëª¨ë“  ë¬¸ì„œê°€ ì„±ê³µì ìœ¼ë¡œ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤."
                    success = True
                else:
                    message = f"ì‚¬ìš©ì '{user_id}'ì˜ ë¬¸ì„œ ì»¬ë ‰ì…˜ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤."
                    success = False
                    
            except Exception as collection_error:
                logger.warning(f"ì»¬ë ‰ì…˜ ì‚­ì œ ì‹¤íŒ¨, ê°œë³„ ì  ì‚­ì œë¡œ ì „í™˜: {collection_error}")
                
                # ì»¬ë ‰ì…˜ ì‚­ì œê°€ ì‹¤íŒ¨í•˜ë©´ ëª¨ë“  ì  ê°œë³„ ì‚­ì œ
                from app.core.embedding_manager import embedding_manager
                await embedding_manager.initialize()
                
                # ë”ë¯¸ ê²€ìƒ‰ìœ¼ë¡œ ëª¨ë“  ì  ê°€ì ¸ì˜¤ê¸°
                test_embedding = await embedding_manager.embed_text("test")
                all_docs = await vector_store.search_similar(
                    collection_name=collection_name,
                    query_vector=test_embedding,
                    limit=50000,  # ë§¤ìš° í° ìˆ˜
                    score_threshold=0.0
                )
                
                if all_docs:
                    # ëª¨ë“  ì ì˜ ID ìˆ˜ì§‘
                    all_point_ids = [doc.document_id for doc in all_docs]
                    
                    # ë°°ì¹˜ë¡œ ì‚­ì œ (Qdrant ì œí•œ ê³ ë ¤)
                    batch_size = 1000
                    total_deleted = 0
                    
                    for i in range(0, len(all_point_ids), batch_size):
                        batch_ids = all_point_ids[i:i + batch_size]
                        from qdrant_client.models import PointIdsList
                        await asyncio.to_thread(
                            vector_store.client.delete,
                            collection_name=collection_name,
                            points_selector=PointIdsList(points=batch_ids)
                        )
                        total_deleted += len(batch_ids)
                        logger.info(f"ë°°ì¹˜ ì‚­ì œ ì§„í–‰: {total_deleted}/{len(all_point_ids)}")
                    
                    deleted_count = total_deleted
                    message = f"ì‚¬ìš©ì '{user_id}'ì˜ ëª¨ë“  ë¬¸ì„œê°€ ì„±ê³µì ìœ¼ë¡œ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤. ({total_deleted}ê°œ ì²­í¬ ì‚­ì œë¨)"
                    success = True
                else:
                    message = f"ì‚¬ìš©ì '{user_id}'ì˜ ë¬¸ì„œê°€ ì´ë¯¸ ë¹„ì–´ìˆìŠµë‹ˆë‹¤."
                    success = False
                
        except Exception as vector_error:
            logger.error(f"ë²¡í„° DB ì „ì²´ ì‚­ì œ ì‹¤íŒ¨: {vector_error}")
            raise HTTPException(
                status_code=500,
                detail=f"ì „ì²´ ë¬¸ì„œ ì‚­ì œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(vector_error)}"
            )
        
        return DocumentDeleteResponse(
            message=message,
            deleted_chunks=deleted_count if isinstance(deleted_count, int) else 0,
            success=success
        )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"ì „ì²´ íŒŒì¼ ì‚­ì œ ì‹¤íŒ¨: {e}")
        raise HTTPException(
            status_code=500,
            detail=f"ì „ì²´ ë¬¸ì„œ ì‚­ì œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
        )


@router.delete("/delete-by-name/{filename}")
async def delete_document_by_name(filename: str, user_id: str = "anonymous") -> DocumentDeleteResponse:
    """íŒŒì¼ëª…ìœ¼ë¡œ ë¬¸ì„œ ì‚­ì œ - ë²¡í„° DBì—ì„œë§Œ ì‚­ì œ"""
    try:
        # ë²¡í„° DBì—ì„œ í•´ë‹¹ íŒŒì¼ëª…ì„ ê°€ì§„ ë¬¸ì„œë“¤ ê²€ìƒ‰
        deleted_from_vector_db = False
        deleted_count = 0
        
        try:
            # ë²¡í„° DB ì´ˆê¸°í™”
            await vector_store.initialize()
            collection_name = f"documents_{user_id}"
            
            # filenameì„ ê¸°ì¤€ìœ¼ë¡œ ì‚­ì œ
            deleted_count = await _delete_document_by_filename(collection_name, filename)
            
            if deleted_count > 0:
                deleted_from_vector_db = True
                logger.info(f"ë²¡í„° DBì—ì„œ {deleted_count}ê°œ ì²­í¬ ì‚­ì œ (íŒŒì¼ëª…: {filename})")
            else:
                logger.warning(f"ì‚­ì œí•  íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ: {filename}")
                
        except Exception as vector_error:
            logger.error(f"ë²¡í„° DB ì‚­ì œ ì‹¤íŒ¨: {vector_error}")
            raise HTTPException(
                status_code=500,
                detail=f"ë¬¸ì„œ ì‚­ì œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(vector_error)}"
            )
        
        if deleted_from_vector_db:
            message = f"íŒŒì¼ '{filename}'ì´ ì„±ê³µì ìœ¼ë¡œ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤. ({deleted_count}ê°œ ì²­í¬ ì‚­ì œë¨)"
            success = True
        else:
            message = f"íŒŒì¼ '{filename}'ì„ ì°¾ì„ ìˆ˜ ì—†ì–´ ì‚­ì œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
            success = False
            
        return DocumentDeleteResponse(
            message=message, 
            deleted_chunks=deleted_count,
            success=success
        )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"íŒŒì¼ ì‚­ì œ ì‹¤íŒ¨: {e}")
        raise HTTPException(
            status_code=500,
            detail=f"íŒŒì¼ ì‚­ì œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
        )


@router.get("/vector-status")
async def get_vector_status() -> Dict[str, Any]:
    """ë²¡í„° DB(Qdrant) ìƒíƒœ ì¡°íšŒ"""
    try:
        await vector_store.initialize()
        
        # Qdrant ì»¬ë ‰ì…˜ ì •ë³´ ì¡°íšŒ
        status = await vector_store.get_collection_info()
        
        return {
            "qdrant_status": "connected",
            "collection_info": status,
            "message": "ë²¡í„° DBê°€ ì •ìƒì ìœ¼ë¡œ ì—°ê²°ë˜ì–´ ìˆìŠµë‹ˆë‹¤"
        }
        
    except Exception as e:
        logger.error(f"ë²¡í„° DB ìƒíƒœ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        return {
            "qdrant_status": "error",
            "collection_info": None,
            "message": f"ë²¡í„° DB ì—°ê²° ì˜¤ë¥˜: {str(e)}"
        }


@router.get("/search-test")
async def test_vector_search(query: str = "í…ŒìŠ¤íŠ¸") -> Dict[str, Any]:
    """ë²¡í„° ê²€ìƒ‰ í…ŒìŠ¤íŠ¸"""
    try:
        from app.core.embedding_manager import embedding_manager
        from app.core.rag_engine import rag_engine
        
        # RAG ì—”ì§„ ì´ˆê¸°í™” ë° ê²€ìƒ‰ í…ŒìŠ¤íŠ¸
        await rag_engine.initialize()
        
        # ì„ë² ë”© ìƒì„±
        query_embedding = await embedding_manager.embed_text(query)
        
        # ë²¡í„° ê²€ìƒ‰
        results = await vector_store.search_similar(
            collection_name="documents_test_user",
            query_vector=query_embedding,
            limit=3,
            score_threshold=0.0  # ëª¨ë“  ê²°ê³¼ ë°˜í™˜
        )
        
        return {
            "query": query,
            "results_count": len(results),
            "results": [
                {
                    "content": result.content[:200] + "..." if len(result.content) > 200 else result.content,
                    "score": result.score,
                    "metadata": result.metadata
                }
                for result in results
            ]
        }
        
    except Exception as e:
        logger.error(f"ë²¡í„° ê²€ìƒ‰ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        raise HTTPException(
            status_code=500,
            detail=f"ë²¡í„° ê²€ìƒ‰ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {str(e)}"
        )


@router.websocket("/ws/progress/{document_id}")
async def websocket_progress(websocket: WebSocket, document_id: str):
    """ë¬¸ì„œ ì²˜ë¦¬ ì§„í–‰ë¥ ì„ ì‹¤ì‹œê°„ìœ¼ë¡œ ìŠ¤íŠ¸ë¦¬ë°"""
    try:
        from app.core.websocket_manager import progress_websocket
        
        await progress_websocket.connect(websocket, document_id)
        logger.info(f"WebSocket ì—°ê²°ë¨: {document_id}")
        
        try:
            while True:
                # í´ë¼ì´ì–¸íŠ¸ë¡œë¶€í„° ë©”ì‹œì§€ ëŒ€ê¸° (ì—°ê²° ìœ ì§€)
                data = await websocket.receive_text()
                
                # í•‘/í° ë©”ì‹œì§€ ì²˜ë¦¬
                if data == "ping":
                    await websocket.send_text("pong")
                    
        except WebSocketDisconnect:
            logger.info(f"WebSocket ì—°ê²° í•´ì œë¨: {document_id}")
        finally:
            await progress_websocket.disconnect(websocket, document_id)
            
    except Exception as e:
        logger.error(f"WebSocket ì˜¤ë¥˜: {e}")
        try:
            await progress_websocket.disconnect(websocket, document_id)
        except:
            pass